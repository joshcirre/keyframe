import Foundation
import AudioToolbox

/// Represents a channel configuration generated by AI
struct AIGeneratedChannel: Codable {
    let instrumentName: String
    let presetName: String?
    let effects: [AIGeneratedEffect]
    let suggestedName: String
    let reasoning: String?
}

struct AIGeneratedEffect: Codable {
    let effectName: String
    let presetName: String?
}

/// Complete AI-generated session setup
struct AIGeneratedSetup: Codable {
    let channels: [AIGeneratedChannel]
    let summary: String
}

/// Errors that can occur during AI preset generation
enum AIPresetGeneratorError: LocalizedError {
    case noAPIKey
    case catalogNotReady
    case networkError(Error)
    case invalidResponse
    case parseError(String)
    
    var errorDescription: String? {
        switch self {
        case .noAPIKey:
            return "API key not configured. Please add your API key in settings."
        case .catalogNotReady:
            return "Plugin catalog is not ready. Please wait for scanning to complete."
        case .networkError(let error):
            return "Network error: \(error.localizedDescription)"
        case .invalidResponse:
            return "Received an invalid response from the AI service."
        case .parseError(let message):
            return "Failed to parse AI response: \(message)"
        }
    }
}

/// Service that generates channel presets using AI based on natural language prompts
@Observable
@MainActor
final class AIPresetGeneratorService {
    
    static let shared = AIPresetGeneratorService()
    
    private(set) var isGenerating = false
    private(set) var lastError: AIPresetGeneratorError?
    
    // MARK: - API Configuration
    
    /// Set your API key here for personal use, or leave empty to require user configuration
    private static let bundledAnthropicKey = ""  // e.g., "sk-ant-..."
    private static let bundledOpenAIKey = ""     // e.g., "sk-..."
    
    /// API key - uses bundled key if available, otherwise falls back to user-configured
    var apiKey: String {
        get {
            let userKey = UserDefaults.standard.string(forKey: "ai_api_key") ?? ""
            if !userKey.isEmpty { return userKey }
            
            // Fall back to bundled key based on provider
            switch apiProvider {
            case .anthropic: return Self.bundledAnthropicKey
            case .openai: return Self.bundledOpenAIKey
            }
        }
        set { UserDefaults.standard.set(newValue, forKey: "ai_api_key") }
    }
    
    /// API provider selection
    var apiProvider: AIProvider {
        get { 
            AIProvider(rawValue: UserDefaults.standard.string(forKey: "ai_provider") ?? "anthropic") ?? .anthropic
        }
        set { UserDefaults.standard.set(newValue.rawValue, forKey: "ai_provider") }
    }
    
    /// Whether we have a usable API key (bundled or user-configured)
    var hasAPIKey: Bool {
        !apiKey.isEmpty
    }
    
    enum AIProvider: String, CaseIterable {
        case anthropic = "anthropic"
        case openai = "openai"
        
        var displayName: String {
            switch self {
            case .anthropic: return "Anthropic (Claude)"
            case .openai: return "OpenAI (GPT-5 Mini)"
            }
        }
    }
    
    private init() {}
    
    /// Generate a channel setup based on user prompt
    func generateSetup(prompt: String) async throws -> AIGeneratedSetup {
        guard !apiKey.isEmpty else {
            throw AIPresetGeneratorError.noAPIKey
        }
        
        let catalog = PluginCatalogService.shared
        guard !catalog.isScanning && !catalog.instrumentCatalog.isEmpty else {
            throw AIPresetGeneratorError.catalogNotReady
        }
        
        isGenerating = true
        lastError = nil
        
        defer { isGenerating = false }
        
        let catalogSummary = catalog.getCatalogSummary()
        let systemPrompt = buildSystemPrompt(catalogSummary: catalogSummary)
        
        do {
            let response: String
            switch apiProvider {
            case .anthropic:
                response = try await callAnthropicAPI(systemPrompt: systemPrompt, userPrompt: prompt)
            case .openai:
                response = try await callOpenAIAPI(systemPrompt: systemPrompt, userPrompt: prompt)
            }
            
            return try parseResponse(response)
        } catch let error as AIPresetGeneratorError {
            lastError = error
            throw error
        } catch {
            let wrappedError = AIPresetGeneratorError.networkError(error)
            lastError = wrappedError
            throw wrappedError
        }
    }
    
    /// Apply the generated setup to the current session
    func applySetup(_ setup: AIGeneratedSetup, midiSourceName: String? = "__none__") async {
        let catalog = PluginCatalogService.shared
        let sessionStore = SessionStore.shared
        let audioEngine = AudioEngine.shared
        
        // Track which strips we create for preset application
        var createdStrips: [(ChannelStrip, AIGeneratedChannel)] = []
        
        for (channelIndex, generatedChannel) in setup.channels.enumerated() {
            // Find the instrument in our catalog
            guard let instrumentEntry = catalog.findInstrument(named: generatedChannel.instrumentName) else {
                print("AIPresetGenerator: Could not find instrument '\(generatedChannel.instrumentName)'")
                continue
            }
            
            // Create the channel strip in audio engine
            guard let strip = audioEngine.addChannel() else {
                print("AIPresetGenerator: Failed to add channel strip")
                continue
            }
            
            // Update strip name
            strip.name = generatedChannel.suggestedName
            
            // Load instrument and wait for it to fully initialize
            let instrumentSuccess = await withCheckedContinuation { continuation in
                strip.loadInstrument(instrumentEntry.componentDescription) { success, error in
                    if !success {
                        print("AIPresetGenerator: Failed to load instrument '\(instrumentEntry.name)': \(error?.localizedDescription ?? "unknown")")
                    }
                    continuation.resume(returning: success)
                }
            }
            
            guard instrumentSuccess else {
                print("AIPresetGenerator: Skipping channel \(channelIndex) due to instrument load failure")
                continue
            }
            
            // Small delay to allow audio engine to stabilize after instrument load
            try? await Task.sleep(nanoseconds: 50_000_000) // 50ms
            
            // Store AUv3Info for the instrument
            strip.instrumentInfo = AUv3Info(
                name: instrumentEntry.name,
                manufacturerName: instrumentEntry.manufacturerName,
                componentType: instrumentEntry.componentDescription.componentType,
                componentSubType: instrumentEntry.componentDescription.componentSubType,
                componentManufacturer: instrumentEntry.componentDescription.componentManufacturer
            )
            
            // Load effects sequentially with delays
            for generatedEffect in generatedChannel.effects {
                guard let effectEntry = catalog.findEffect(named: generatedEffect.effectName) else {
                    print("AIPresetGenerator: Could not find effect '\(generatedEffect.effectName)'")
                    continue
                }
                
                await withCheckedContinuation { continuation in
                    strip.addEffect(effectEntry.componentDescription) { success, error in
                        if !success {
                            print("AIPresetGenerator: Failed to load effect '\(effectEntry.name)': \(error?.localizedDescription ?? "unknown")")
                        }
                        continuation.resume()
                    }
                }
                
                // Store effect info
                strip.effectInfos.append(AUv3Info(
                    name: effectEntry.name,
                    manufacturerName: effectEntry.manufacturerName,
                    componentType: effectEntry.componentDescription.componentType,
                    componentSubType: effectEntry.componentDescription.componentSubType,
                    componentManufacturer: effectEntry.componentDescription.componentManufacturer
                ))
                
                // Small delay between effects
                try? await Task.sleep(nanoseconds: 30_000_000) // 30ms
            }
            
            // Set MIDI source on the strip
            strip.midiSourceName = midiSourceName
            
            createdStrips.append((strip, generatedChannel))
            
            // Ensure audio chain connections after each channel is fully loaded
            audioEngine.ensureChannelConnections()
            
            // Delay between channels to allow audio engine to stabilize
            if channelIndex < setup.channels.count - 1 {
                try? await Task.sleep(nanoseconds: 100_000_000) // 100ms between channels
            }
            
            // Create channel configuration for session persistence
            var channelConfig = ChannelConfiguration(
                id: strip.id,
                name: generatedChannel.suggestedName,
                midiSourceName: midiSourceName
            )
            
            // Set up instrument plugin configuration
            channelConfig.instrument = PluginConfiguration(
                name: instrumentEntry.name,
                manufacturerName: instrumentEntry.manufacturerName,
                componentType: instrumentEntry.componentDescription.componentType,
                componentSubType: instrumentEntry.componentDescription.componentSubType,
                componentManufacturer: instrumentEntry.componentDescription.componentManufacturer
            )
            
            // Add effect configurations
            for generatedEffect in generatedChannel.effects {
                if let effectEntry = catalog.findEffect(named: generatedEffect.effectName) {
                    let effectConfig = PluginConfiguration(
                        name: effectEntry.name,
                        manufacturerName: effectEntry.manufacturerName,
                        componentType: effectEntry.componentDescription.componentType,
                        componentSubType: effectEntry.componentDescription.componentSubType,
                        componentManufacturer: effectEntry.componentDescription.componentManufacturer
                    )
                    channelConfig.effects.append(effectConfig)
                }
            }
            
            // Add to session
            sessionStore.currentSession.channels.append(channelConfig)
        }
        
        // Final verification: ensure all channels are properly connected
        print("AIPresetGenerator: Verifying \(createdStrips.count) channel connections...")
        audioEngine.ensureChannelConnections()
        
        // Apply factory presets to newly loaded instruments
        await applyFactoryPresets(createdStrips, catalog: catalog)
        
        // Small delay to allow presets to apply
        try? await Task.sleep(nanoseconds: 50_000_000) // 50ms
        
        // Save session
        sessionStore.saveCurrentSession()
        
        print("AIPresetGenerator: Setup complete - \(createdStrips.count) channels created")
    }
    
    /// Apply factory presets after instruments are loaded
    private func applyFactoryPresets(_ createdStrips: [(ChannelStrip, AIGeneratedChannel)], catalog: PluginCatalogService) async {
        for (strip, generatedChannel) in createdStrips {
            // Apply instrument factory preset if specified
            if let presetName = generatedChannel.presetName,
               let instrumentEntry = catalog.findInstrument(named: generatedChannel.instrumentName),
               let preset = catalog.findPreset(named: presetName, in: instrumentEntry),
               let instrument = strip.instrument {
                
                // Find the matching factory preset from the audio unit
                if let factoryPreset = instrument.auAudioUnit.factoryPresets?.first(where: { $0.number == preset.id }) {
                    instrument.auAudioUnit.currentPreset = factoryPreset
                    print("AIPresetGenerator: Applied preset '\(preset.name)' to \(instrumentEntry.name)")
                }
            }
            
            // Apply effect factory presets
            for (effectIndex, generatedEffect) in generatedChannel.effects.enumerated() {
                guard effectIndex < strip.effects.count,
                      let presetName = generatedEffect.presetName,
                      let effectEntry = catalog.findEffect(named: generatedEffect.effectName),
                      let preset = catalog.findPreset(named: presetName, in: effectEntry) else {
                    continue
                }
                
                let effect = strip.effects[effectIndex]
                // Find the matching factory preset from the audio unit
                if let factoryPreset = effect.auAudioUnit.factoryPresets?.first(where: { $0.number == preset.id }) {
                    effect.auAudioUnit.currentPreset = factoryPreset
                    print("AIPresetGenerator: Applied preset '\(preset.name)' to \(effectEntry.name)")
                }
            }
        }
    }
    
    // MARK: - API Calls
    
    private func callAnthropicAPI(systemPrompt: String, userPrompt: String) async throws -> String {
        let url = URL(string: "https://api.anthropic.com/v1/messages")!
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        request.setValue(apiKey, forHTTPHeaderField: "x-api-key")
        request.setValue("2023-06-01", forHTTPHeaderField: "anthropic-version")
        
        let body: [String: Any] = [
            "model": "claude-sonnet-4-20250514",
            "max_tokens": 2048,
            "system": systemPrompt,
            "messages": [
                ["role": "user", "content": userPrompt]
            ]
        ]
        
        request.httpBody = try JSONSerialization.data(withJSONObject: body)
        
        let (data, response) = try await URLSession.shared.data(for: request)
        
        guard let httpResponse = response as? HTTPURLResponse else {
            throw AIPresetGeneratorError.invalidResponse
        }
        
        // Log response for debugging
        if let responseString = String(data: data, encoding: .utf8) {
            print("AIPresetGenerator [Anthropic] Status: \(httpResponse.statusCode)")
            print("AIPresetGenerator [Anthropic] Response: \(responseString.prefix(500))")
        }
        
        guard (200...299).contains(httpResponse.statusCode) else {
            throw AIPresetGeneratorError.parseError("API returned status \(httpResponse.statusCode)")
        }
        
        guard let json = try JSONSerialization.jsonObject(with: data) as? [String: Any],
              let content = json["content"] as? [[String: Any]],
              let firstContent = content.first,
              let text = firstContent["text"] as? String else {
            throw AIPresetGeneratorError.invalidResponse
        }
        
        return text
    }
    
    private func callOpenAIAPI(systemPrompt: String, userPrompt: String) async throws -> String {
        let url = URL(string: "https://api.openai.com/v1/chat/completions")!
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        request.setValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")
        
        // Define the tool for creating channel setups
        let createChannelsTool: [String: Any] = [
            "type": "function",
            "function": [
                "name": "create_channel_setup",
                "description": "Create a multi-channel instrument setup based on user's sound description",
                "parameters": [
                    "type": "object",
                    "properties": [
                        "channels": [
                            "type": "array",
                            "description": "List of channels to create",
                            "items": [
                                "type": "object",
                                "properties": [
                                    "instrumentName": [
                                        "type": "string",
                                        "description": "Exact name of the instrument plugin"
                                    ],
                                    "presetName": [
                                        "type": "string",
                                        "description": "Factory preset name, or null for default"
                                    ],
                                    "effects": [
                                        "type": "array",
                                        "items": [
                                            "type": "object",
                                            "properties": [
                                                "effectName": ["type": "string"],
                                                "presetName": ["type": "string"]
                                            ],
                                            "required": ["effectName"]
                                        ]
                                    ],
                                    "suggestedName": [
                                        "type": "string",
                                        "description": "Short channel name"
                                    ],
                                    "reasoning": [
                                        "type": "string",
                                        "description": "Brief explanation"
                                    ]
                                ],
                                "required": ["instrumentName", "suggestedName", "effects"]
                            ]
                        ],
                        "summary": [
                            "type": "string",
                            "description": "One sentence overview of the setup"
                        ]
                    ],
                    "required": ["channels", "summary"]
                ]
            ]
        ]
        
        // GPT-5 series parameters with tool calling
        let body: [String: Any] = [
            "model": "gpt-5-mini",
            "max_completion_tokens": 2048,
            "reasoning_effort": "low",
            "verbosity": "low",
            "messages": [
                ["role": "system", "content": systemPrompt],
                ["role": "user", "content": userPrompt]
            ],
            "tools": [createChannelsTool],
            "tool_choice": ["type": "function", "function": ["name": "create_channel_setup"]]
        ]
        
        request.httpBody = try JSONSerialization.data(withJSONObject: body)
        
        let (data, response) = try await URLSession.shared.data(for: request)
        
        guard let httpResponse = response as? HTTPURLResponse else {
            throw AIPresetGeneratorError.invalidResponse
        }
        
        // Log response for debugging
        if let responseString = String(data: data, encoding: .utf8) {
            print("AIPresetGenerator [OpenAI] Status: \(httpResponse.statusCode)")
            print("AIPresetGenerator [OpenAI] Response: \(responseString.prefix(1000))")
        }
        
        guard (200...299).contains(httpResponse.statusCode) else {
            throw AIPresetGeneratorError.parseError("API returned status \(httpResponse.statusCode)")
        }
        
        // Parse tool call response
        guard let json = try JSONSerialization.jsonObject(with: data) as? [String: Any],
              let choices = json["choices"] as? [[String: Any]],
              let firstChoice = choices.first,
              let message = firstChoice["message"] as? [String: Any],
              let toolCalls = message["tool_calls"] as? [[String: Any]],
              let firstToolCall = toolCalls.first,
              let function = firstToolCall["function"] as? [String: Any],
              let arguments = function["arguments"] as? String else {
            // Fallback: try to get content directly (in case model doesn't use tool)
            if let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
               let choices = json["choices"] as? [[String: Any]],
               let firstChoice = choices.first,
               let message = firstChoice["message"] as? [String: Any],
               let content = message["content"] as? String {
                return content
            }
            throw AIPresetGeneratorError.invalidResponse
        }
        
        // The arguments string is the JSON we need
        return arguments
    }
    
    // MARK: - Prompt Building
    
    private func buildSystemPrompt(catalogSummary: String) -> String {
        """
        You are an expert music producer and sound designer assistant for a MIDI keyboard/synthesizer app called Keyframe. \
        Your job is to help users set up their instrument channels based on their descriptions.

        The user will describe what kind of sound or setup they want, and you must select the best matching \
        instruments and effects from the available catalog, along with appropriate factory presets.

        IMPORTANT RULES:
        1. Only use instruments and effects that exist in the catalog provided below
        2. Use the EXACT plugin name as shown (e.g., "King of FM" not "King of FM (AudioKit)")
        3. Do NOT add manufacturer names in parentheses - just use the plugin name exactly as listed
        4. Match preset names EXACTLY as they appear in the catalog
        5. If no factory preset matches well, set presetName to null (the default sound will be used)
        6. PREFER third-party effects over Apple built-in effects (avoid AUReverb2, AUDelay, AUDistortion, etc.)
        7. Be creative but practical - suggest realistic combinations
        8. Consider the user's described use case (live performance, recording, practice, etc.)
        9. Limit to 1-4 channels unless the user specifically asks for more

        You MUST respond with ONLY valid JSON in this exact format (no markdown, no explanation outside the JSON):
        {
            "channels": [
                {
                    "instrumentName": "Exact Plugin Name",
                    "presetName": "Exact Preset Name or null",
                    "effects": [
                        {
                            "effectName": "Exact Effect Name",
                            "presetName": "Exact Preset Name or null"
                        }
                    ],
                    "suggestedName": "Short descriptive channel name",
                    "reasoning": "Brief explanation of why this was chosen"
                }
            ],
            "summary": "One sentence overview of the setup"
        }

        AVAILABLE PLUGINS AND PRESETS:
        
        \(catalogSummary)
        """
    }
    
    // MARK: - Response Parsing
    
    private func parseResponse(_ response: String) throws -> AIGeneratedSetup {
        // Extract JSON from response (in case there's any surrounding text)
        let jsonString: String
        if let startIndex = response.firstIndex(of: "{"),
           let endIndex = response.lastIndex(of: "}") {
            jsonString = String(response[startIndex...endIndex])
        } else {
            throw AIPresetGeneratorError.parseError("No JSON object found in response")
        }
        
        guard let data = jsonString.data(using: .utf8) else {
            throw AIPresetGeneratorError.parseError("Could not convert response to data")
        }
        
        do {
            let setup = try JSONDecoder().decode(AIGeneratedSetup.self, from: data)
            return setup
        } catch {
            throw AIPresetGeneratorError.parseError(error.localizedDescription)
        }
    }
}
